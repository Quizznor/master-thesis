{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Binaries import *\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For VEM Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_evolution = []\n",
    "trigger_examples = []\n",
    "cut_threshold = 30\n",
    "leading_bins = 20\n",
    "trailing_bins = 49\n",
    "multiplicity = 1\n",
    "dead_time = trailing_bins\n",
    "combine_files = 30\n",
    "station_name = \"nuria\"\n",
    "\n",
    "mode = \"peak\"\n",
    "\n",
    "if mode == \"peak\":\n",
    "\n",
    "    x_range = (cut_threshold, 1200)\n",
    "    i, f = 20, 100\n",
    "    func = max\n",
    "    min_vem = 120\n",
    "    calibration_guess = GLOBAL.q_peak\n",
    "    std = 10\n",
    "\n",
    "elif mode == \"charge\":\n",
    "\n",
    "    x_range = (cut_threshold, 12000)\n",
    "    i, f = 20, 70\n",
    "    func = sum\n",
    "    min_vem = 1000\n",
    "    calibration_guess = GLOBAL.q_charge\n",
    "    std = 200\n",
    "\n",
    "first_trigger = lambda x : np.argmax(x > cut_threshold)\n",
    "\n",
    "def gauss(x, mu, A, sigma):\n",
    "\n",
    "    return A * np.exp( -(x - mu)**2 / (2 * sigma**2) )\n",
    "\n",
    "def background(x, A, c):\n",
    "\n",
    "    return A - (x - min_vem) * c\n",
    "\n",
    "colors = [\"steelblue\", \"orange\", \"green\"]\n",
    "\n",
    "h1, h2, h3 = [], [], []\n",
    "\n",
    "for index in range(0, len(os.listdir(f\"/cr/tempdata01/filip/iRODS/{station_name}/\")), 3):\n",
    "\n",
    "    for increment in range(combine_files):\n",
    "\n",
    "        Buffer = RandomTrace(station_name, index + increment)\n",
    "        \n",
    "        vem_peak = []\n",
    "\n",
    "        # print(f\"{index + increment}/{Buffer.all_n_files} {Buffer.random_file}: {len(Buffer._these_traces)} traces\", end = \"\\r\")\n",
    "\n",
    "        station = np.array(Buffer._these_traces)\n",
    "        pmt1, pmt2, pmt3 = station[:,0], station[:,1], station[:,2]\n",
    "        cut_mask = np.logical_and(np.any(pmt1 > cut_threshold, axis = 1), np.any(pmt2 > cut_threshold, axis = 1), np.any(pmt3 > cut_threshold, axis = 1))\n",
    "\n",
    "        for (p1, p2, p3) in zip(pmt1[cut_mask], pmt2[cut_mask], pmt3[cut_mask]):\n",
    "\n",
    "            steps = iter(range(min([first_trigger(p1), first_trigger(p2), first_trigger(p3)]), 2048))\n",
    "            # STRONG COINCIDENCE\n",
    "            for step in steps:\n",
    "\n",
    "                trigger_list = [p1[step] > cut_threshold, p2[step] > cut_threshold, p3[step] > cut_threshold]\n",
    "\n",
    "                if trigger_list.count(True) >= multiplicity:\n",
    "\n",
    "                    start, stop = max(0, step - leading_bins), min(2048, step + trailing_bins)\n",
    "\n",
    "                    p1_data, p2_data, p3_data = p1[start : stop], p2[start : stop], p3[start : stop]\n",
    "                    h1.append(func(p1_data)), h2.append(func(p2_data)), h3.append(func(p3_data))\n",
    "\n",
    "                    if len(trigger_examples) < 100: trigger_examples.append([p1_data, p2_data, p3_data])\n",
    "\n",
    "                    for _ in range(dead_time): next(steps, None)\n",
    "                    # step += dead_time       # keep iterating\n",
    "                    # break                     # stop after first hit\n",
    "        \n",
    "            # # WEAK COINCIDENCE\n",
    "            # trigger_bin = np.argmax(p1 > cut_threshold)\n",
    "            # start = max(0, trigger_bin - leading_bins)\n",
    "            # stop = min(trigger_bin + trailing_bins, 2048)\n",
    "\n",
    "            # p1_data, p2_data, p3_data = p1[start : stop], p2[start : stop], p3[start : stop]\n",
    "\n",
    "            # if np.any(p2_data > cut_threshold) and np.any(p3_data > cut_threshold):\n",
    "\n",
    "            #     h1.append(func(p1_data)), h2.append(func(p2_data)), h3.append(func(p3_data))\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, sharex = True)\n",
    "    name = Buffer.random_file.split(\"_\")[0]\n",
    "\n",
    "    try:\n",
    "        for j, histogram in enumerate([h1, h2, h3]):\n",
    "\n",
    "            n, bins, _ = axes[j].hist(histogram,  bins = 250, range = x_range, label = f\"{len(histogram)} coincidences\", ls = \"solid\", histtype = \"step\", color = colors[j], lw = 1)\n",
    "            bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "            # Signal region\n",
    "            x, y = bin_centers[i : f], n[i : f]\n",
    "            x_smooth = np.linspace(min(x), max(x), 100)\n",
    "\n",
    "            x_out = list(bin_centers[0 : i]) + list(bin_centers[f : -1])\n",
    "            y_out = list(n[0 : i]) + list(n[f : -1])\n",
    "            x_out_smooth = np.linspace(min(x_out), max(x_out), 100)\n",
    "\n",
    "            # fitting background exponential first\n",
    "            y_out_log = np.log(y_out)\n",
    "            y_out_log[y_out_log == -np.inf] = 0\n",
    "            popt_background, pcov_background = curve_fit(background, x_out, y_out_log, p0 = [y_out_log[0], 0.2], bounds = ([0, 0], [np.inf, np.inf]))\n",
    "            background_fit = np.exp(background(x_out_smooth, *popt_background))\n",
    "\n",
    "            # fitting signal region with substracted background\n",
    "            popt, pcov = curve_fit(gauss, x, y - np.exp(background(x, *popt_background)), p0 = [calibration_guess, min_vem, std], bounds = ([0, 0, 0], [np.inf, np.inf, np.inf]) )\n",
    "            model_fit = gauss(x_smooth, *popt) + np.exp(background(x_smooth, *popt_background))\n",
    "            peak_estimate = popt[0]\n",
    "                    \n",
    "\n",
    "            label = r\"$\\mathrm{VEM}_\\mathrm{Peak} = $\" if mode == \"peak\" else r\"$\\mathrm{VEM}_\\mathrm{Charge} = $\"\n",
    "            label += f\"{peak_estimate:.3f} +- {np.sqrt(pcov[0][0]):.2e}\"\n",
    "\n",
    "            axes[j].plot(x_smooth, model_fit, label = label, c = colors[j], ls = \"--\", lw = 2)\n",
    "            axes[j].plot(x_out_smooth, background_fit, c = \"gray\", ls = \"--\", lw = 2)\n",
    "            axes[j].legend(title = f\"Station {name.capitalize()} - PMT #{j + 1}\")\n",
    "            axes[j].set_yscale(\"log\")\n",
    "\n",
    "            axes[j].set_ylim(10e-1, 1.1 * max(n))\n",
    "\n",
    "            axes[-1].set_xlabel(\"VEM peak\")\n",
    "\n",
    "            # if peak_estimate <= min_vem: raise SignalError\n",
    "\n",
    "            vem_peak.append(peak_estimate)\n",
    "\n",
    "        peak_evolution.append(vem_peak)\n",
    "\n",
    "        axes[-1].set_xlabel(\"VEM peak\")\n",
    "\n",
    "    except SignalError:\n",
    "\n",
    "        for increment in range(combine_files):\n",
    "\n",
    "            filename = f\"{station_name}/{station_name}_randoms{(index + increment).zfill(4)}.csv\"\n",
    "            # os.system(f\"mv /cr/tempdata01/filip/iRODS/{station_name}/{filename} /cr/tempdata01/filip/iRODS/faulty_estimate/{filename}\")\n",
    "            print(f\"mv /cr/tempdata01/filip/iRODS/{station_name}/{filename} /cr/tempdata01/filip/iRODS/faulty_estimate/{filename}\")\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For VEM Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_evolution = []\n",
    "trigger_examples = []\n",
    "cut_threshold = 30\n",
    "leading_bins = 20\n",
    "trailing_bins = 49\n",
    "multiplicity = 1\n",
    "dead_time = trailing_bins\n",
    "combine_files = 30\n",
    "station_name = \"nuria\"\n",
    "\n",
    "mode = \"charge\"\n",
    "\n",
    "if mode == \"peak\":\n",
    "\n",
    "    x_range = (cut_threshold, 1200)\n",
    "    i, f = 20, 100\n",
    "    func = max\n",
    "    min_vem = 120\n",
    "    calibration_guess = GLOBAL.q_peak\n",
    "    std = 10\n",
    "\n",
    "elif mode == \"charge\":\n",
    "\n",
    "    x_range = (cut_threshold, 12000)\n",
    "    i, f = 20, 70\n",
    "    func = sum\n",
    "    min_vem = 1000\n",
    "    calibration_guess = GLOBAL.q_charge\n",
    "    std = 200\n",
    "\n",
    "first_trigger = lambda x : np.argmax(x > cut_threshold)\n",
    "\n",
    "def gauss(x, mu, A, sigma):\n",
    "\n",
    "    return A * np.exp( -(x - mu)**2 / (2 * sigma**2) )\n",
    "\n",
    "def background(x, A, c):\n",
    "\n",
    "    return A - (x - min_vem) * c\n",
    "\n",
    "colors = [\"steelblue\", \"orange\", \"green\"]\n",
    "\n",
    "h1, h2, h3 = [], [], []\n",
    "\n",
    "for index in range(0, len(os.listdir(f\"/cr/tempdata01/filip/iRODS/{station_name}/\")), 3):\n",
    "\n",
    "    for increment in range(combine_files):\n",
    "\n",
    "        Buffer = RandomTrace(station_name, index + increment)\n",
    "        \n",
    "        vem_peak = []\n",
    "\n",
    "        # print(f\"{index + increment}/{Buffer.all_n_files} {Buffer.random_file}: {len(Buffer._these_traces)} traces\", end = \"\\r\")\n",
    "\n",
    "        station = np.array(Buffer._these_traces)\n",
    "        pmt1, pmt2, pmt3 = station[:,0], station[:,1], station[:,2]\n",
    "        cut_mask = np.logical_and(np.any(pmt1 > cut_threshold, axis = 1), np.any(pmt2 > cut_threshold, axis = 1), np.any(pmt3 > cut_threshold, axis = 1))\n",
    "\n",
    "        for (p1, p2, p3) in zip(pmt1[cut_mask], pmt2[cut_mask], pmt3[cut_mask]):\n",
    "\n",
    "            steps = iter(range(min([first_trigger(p1), first_trigger(p2), first_trigger(p3)]), 2048))\n",
    "            # STRONG COINCIDENCE\n",
    "            for step in steps:\n",
    "\n",
    "                trigger_list = [p1[step] > cut_threshold, p2[step] > cut_threshold, p3[step] > cut_threshold]\n",
    "\n",
    "                if trigger_list.count(True) >= multiplicity:\n",
    "\n",
    "                    start, stop = max(0, step - leading_bins), min(2048, step + trailing_bins)\n",
    "\n",
    "                    p1_data, p2_data, p3_data = p1[start : stop], p2[start : stop], p3[start : stop]\n",
    "                    h1.append(func(p1_data)), h2.append(func(p2_data)), h3.append(func(p3_data))\n",
    "\n",
    "                    if len(trigger_examples) < 100: trigger_examples.append([p1_data, p2_data, p3_data])\n",
    "\n",
    "                    for _ in range(dead_time): next(steps, None)\n",
    "                    # step += dead_time       # keep iterating\n",
    "                    # break                     # stop after first hit\n",
    "        \n",
    "            # # WEAK COINCIDENCE\n",
    "            # trigger_bin = np.argmax(p1 > cut_threshold)\n",
    "            # start = max(0, trigger_bin - leading_bins)\n",
    "            # stop = min(trigger_bin + trailing_bins, 2048)\n",
    "\n",
    "            # p1_data, p2_data, p3_data = p1[start : stop], p2[start : stop], p3[start : stop]\n",
    "\n",
    "            # if np.any(p2_data > cut_threshold) and np.any(p3_data > cut_threshold):\n",
    "\n",
    "            #     h1.append(func(p1_data)), h2.append(func(p2_data)), h3.append(func(p3_data))\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, sharex = True)\n",
    "    name = Buffer.random_file.split(\"_\")[0]\n",
    "\n",
    "    try:\n",
    "        for j, histogram in enumerate([h1, h2, h3]):\n",
    "\n",
    "            n, bins, _ = axes[j].hist(histogram,  bins = 250, range = x_range, label = f\"{len(histogram)} coincidences\", ls = \"solid\", histtype = \"step\", color = colors[j], lw = 1)\n",
    "            bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "            # Signal region\n",
    "            x, y = bin_centers[i : f], n[i : f]\n",
    "            x_smooth = np.linspace(min(x), max(x), 100)\n",
    "\n",
    "            x_out = list(bin_centers[0 : i]) + list(bin_centers[f : -1])\n",
    "            y_out = list(n[0 : i]) + list(n[f : -1])\n",
    "            x_out_smooth = np.linspace(min(x_out), max(x_out), 100)\n",
    "\n",
    "            # fitting background exponential first\n",
    "            y_out_log = np.log(y_out)\n",
    "            y_out_log[y_out_log == -np.inf] = 0\n",
    "            popt_background, pcov_background = curve_fit(background, x_out, y_out_log, p0 = [y_out_log[0], 0.2], bounds = ([0, 0], [np.inf, np.inf]))\n",
    "            background_fit = np.exp(background(x_out_smooth, *popt_background))\n",
    "\n",
    "            # fitting signal region with substracted background\n",
    "            popt, pcov = curve_fit(gauss, x, y - np.exp(background(x, *popt_background)), p0 = [calibration_guess, min_vem, std], bounds = ([0, 0, 0], [np.inf, np.inf, np.inf]) )\n",
    "            model_fit = gauss(x_smooth, *popt) + np.exp(background(x_smooth, *popt_background))\n",
    "            peak_estimate = popt[0]\n",
    "                    \n",
    "\n",
    "            label = r\"$\\mathrm{VEM}_\\mathrm{Peak} = $\" if mode == \"peak\" else r\"$\\mathrm{VEM}_\\mathrm{Charge} = $\"\n",
    "            label += f\"{peak_estimate:.3f} +- {np.sqrt(pcov[0][0]):.2e}\"\n",
    "\n",
    "            axes[j].plot(x_smooth, model_fit, label = label, c = colors[j], ls = \"--\", lw = 2)\n",
    "            axes[j].plot(x_out_smooth, background_fit, c = \"gray\", ls = \"--\", lw = 2)\n",
    "            axes[j].legend(title = f\"Station {name.capitalize()} - PMT #{j + 1}\")\n",
    "            axes[j].set_yscale(\"log\")\n",
    "\n",
    "            axes[j].set_ylim(10e-1, 1.1 * max(n))\n",
    "\n",
    "            axes[-1].set_xlabel(\"VEM peak\")\n",
    "\n",
    "            # if peak_estimate <= min_vem: raise SignalError\n",
    "\n",
    "            vem_peak.append(peak_estimate)\n",
    "\n",
    "        peak_evolution.append(vem_peak)\n",
    "\n",
    "        axes[-1].set_xlabel(\"VEM peak\")\n",
    "\n",
    "    except SignalError:\n",
    "\n",
    "        for increment in range(combine_files):\n",
    "\n",
    "            filename = f\"{station_name}/{station_name}_randoms{(index + increment).zfill(4)}.csv\"\n",
    "            # os.system(f\"mv /cr/tempdata01/filip/iRODS/{station_name}/{filename} /cr/tempdata01/filip/iRODS/faulty_estimate/{filename}\")\n",
    "            print(f\"mv /cr/tempdata01/filip/iRODS/{station_name}/{filename} /cr/tempdata01/filip/iRODS/faulty_estimate/{filename}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (pmt1, pmt2, pmt3) in trigger_examples:\n",
    "\n",
    "    plt.plot(range(len(pmt1)), pmt1)\n",
    "    plt.plot(range(len(pmt2)), pmt2)\n",
    "    plt.plot(range(len(pmt3)), pmt3)\n",
    "    plt.axvline(20, ls = \"--\", c = \"k\")\n",
    "    plt.axhline(30, ls = \":\", c = \"steelblue\", alpha = 0.2)\n",
    "\n",
    "    plt.xlim(0, 69)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    input()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6bd95ed309fd09468b42d789b4c7d801e53518dbe20f43a540524fa8075e3ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
