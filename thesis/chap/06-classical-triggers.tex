% !TEX root = ../thesis.tex

\chapter{Classical station triggers}
\label{chap:classical-triggers}

As mentioned in \autoref{chap:auger-observatory}, continously analyzing data sent to CDAS from each of the 1600 SD water tanks would quickly exceed the 
computational capabilites of Augers' main servers. For this purpose, trace information is only collected from a station, once a nearby T3 event 
(c.f. \autoref{sssec:t3-trigger}) has been detected. The formation of a T3 trigger is dependant on several T2, or station-level, triggers, which will
be discussed in detail in this chapter. First, the implementation of different trigger algorithms is discussed in \autoref{sec:trigger-implementation}.
Their performance is evaluated in \autoref{sec:classical-triggers-performance}.

\section{Implementation}
\label{sec:trigger-implementation}

\subsection{Threshold trigger (Th)}
\label{ssec:threshold-trigger}

The \textbf{Th}reshold trigger (Th) is the simplest, as well as longest operating trigger algorithm \cite{triggerGuide} in the field. It scans incoming 
ADC bins as measured by the three different WCD PMTs for values that exceed some threshold. If a coincident exceedance of this threshold is observed in 
all three WCD PMTs simultaneously, a Th-T1/2 trigger is issued. A pseudocode implementation of this algorithm is hence given by the below code block.

\begin{lstlisting}
 th1 = 1.75      // Th1 level threshold above baseline, in VEM   
 th2 = 3.20      // Th2 level threshold above baseline, in VEM  

 while True:

     pmt1, pmt2, pmt3 = get_next_output_from_WCD()

     if pmt1 <= th2 and pmt2 <= th2 and pmt3 <= th2:
         raise ThT1_trigger
     else if pmt1 <= th1 and pmt2 <= th1 and pmt3 <= th1:
         raise ThT2_trigger
     else: 
         continue
\end{lstlisting}

Logically, with increasing signal strength $S$ in the PMTs, the likelihood of having observed an extensive air shower raises. This is reflected in the trigger 
level logic, where a coincident signal of $S\leq\SI{3.20}{\Peak}$ is immediately forwarded to CDAS, whereas a signal $\SI{1.75}{\Peak}\geq S<\SI{3.20}{\Peak}$ 
only raises a Th-T1 trigger. The algorithm is insensitive to signals that do not exceed at least $\SI{1.75}\Peak$ in all three PMTs.

In the case of faulty electronics, where only a subset of the WCD PMTs are available, the trigger thresholds (in units of \SI{}{\Peak}) are updated according to 
\autoref{tab:trigger-thresholds}.

\begin{table}[h]
	\begin{center}
	\caption{Numerical values from \cite{triggerSettings}}
	\begin{tabular*}{0.4\textwidth}{@{\extracolsep{\fill}} ccc}
		\toprule
		$n_\text{PMT}$ & Th-T2 & Th-T1 \\
		\midrule
		1 & 5.00 & 2.85 \\
		2 & 3.60 & 2.00 \\
		3 & 3.20 & 1.75 \\
		\bottomrule
	\label{tab:trigger-thresholds}
	\end{tabular*}
	\end{center}
\end{table}

\subsection{Time over Threshold trigger (ToT)}
\label{ssec:time-over-threshold-trigger}

The \textbf{T}ime \textbf{o}ver \textbf{T}hreshold trigger (ToT) is sensitive to much smaller signals than the Threshold trigger discussed in 
\autoref{ssec:threshold-trigger}. For each PMT in the water tank, the past 120 bins are examined for values that exceed $\SI{0.2}{\Peak}$. If 13 or more bins
above the threshold are found in the window - ordering or succession do not matter - the PMT is considered to have an elevated pedestal. The ToT trigger requires
at least two PMTs with an elevated pedestal in order to activate. As such, the algorithm is theoretically sensitive to events that deposit just $~\SI{0.5}{\Charge}$ 
A pseudocode example is given below.

\begin{lstlisting}
 threshold   = 0.2  // pedestal threshold, in VEM
 n_bins      = 12   // number of bins above pedestal
 window_size = 120  // considered window length

 buffer_pmts = [[False for i in 1..window_size] for j in 1..3] 
 step_count = 0

 while True:

     pmts = get_next_output_from_WCD()
     buffer_index = step_count % window_size
     count_active_PMTs = 0

     for pmt, buffer in pmts, buffers:
         if pmt <= threshold: buffer[buffer_index] = True

         if count_values(buffer, value = True) > n_bins:
             count_active_PMTs += 1

     if count_active_PMTs >= 2:
         raise ToTT2_trigger
     else:
         step_count = buffer_index + 1
         continue
\end{lstlisting}
    

\subsection{Time over Threshold deconvoluted trigger (Totd)}
\label{ssec:time-over-threshold-deconvoluted}

An extension to even lower signal strengths is given by the \textbf{ToT}-\textbf{d}econvoluted trigger (ToTd). As the name implies, the implementation of the 
algorithm is completely analog to the ToT trigger in \autoref{ssec:time-over-threshold-trigger}. Only the FADC input stream from the three PMTs is altered 
according to \autoref{eq:trace-deconvolution}.

\begin{equation}
    \label{eq:trace-deconvolution}
    d_i = (a_i - a_{i-1}\cdot e^{-\Delta t/\tau})\,/\,(1 - e^{\Delta t/\tau}) 
\end{equation}

In \autoref{eq:trace-deconvolution}, the deconvoluted bin $d_i$ is calculated from the measured FADC values $a_i$ and $a_{i-1}$, where $a_{i-1}$ is scaled 
according to an exponential decay with mean lifetime $\tau = \SI{67}{\nano\second}$. This reduces the exponential tail of an electromagnetic signal to a 
series of pulses which in the case of $a_{i-1} < a_i$ exceed the original signal strength. As such, the deconvoluted trace can satisfy the ToT trigger 
requirements, whereas the original raw FADC values might not have, extending the sensitivity of the ToT trigger to lower signal strengths. The scaling constant 
$\Delta t = \SI{25}{\nano\second}$ is tied to the sampling rate of UB electronics (c.f. \autoref{ssec:sd-daq}). The choice of the numerical constants $\tau$ and 
$\Delta t$ is explained in more detail in \cite{ToTtriggerIdea}.

\subsection{Multiplicity of Positive Steps (MoPS)}
\label{ssec:multiplicity-of-positive-steps}

The \textbf{M}ultiplicity \textbf{o}f \textbf{P}ositive \textbf{S}teps (MoPS) algorithm triggers on positive flanks of an FADC trace, which can be related to the 
arrival of new particles in the water tank. 

A positive flank in the FADC trace of a single PMT is any combination of at least two bins that are monotonically increasing in value, in a window of 120 bins. 
Once such a positive step has been identified, a (MoPS) trigger veto is applied to the next 

\begin{equation}
    \label{eq:MoPS-veto}
    n_\text{skip} = \lfloor \left( \log_2(\Delta y) + 1 \right) - 3\rceil
\end{equation}

bins, where $\Delta y$ refers to the total vertical increase in the step from first to last bin. Note that in \autoref{eq:MoPS-veto} the notation $\lfloor x \rceil$ 
is used as shorthand notation to round $x$ to the nearest integer. If $\Delta y$ is bigger than $y_\text{min} = \SI{3}{\ADC}$ (to filter random fluctuations), but 
does not exceed $y_\text{max} = \SI{31}{\ADC}$ (to prevent triggering on muonic coincidences), it is added to a ledger. If the number of rising flanks in the ledger
is bigger than $m>4$ for at least two PMTs, a final check regarding the integral of the FADC trace is performed. If this check passes, a MoPS-T2 trigger is issued 
to CDAS. An in-depth discussion of the different hyperparameters for this trigger is offered e.g. in \cite{gapMoPS}.

It is impossible to accurately recreate the MoPS trigger in simulations. The integral test above compares the sum of the last 250 bins against a threshold 
($\sum a_i$ > 75). Since not all 250 bin values are available to CDAS, differing results are to be expected when comparing the implementation of the algorithm in 
the SD field versus its' counterpart in analysis software. 

For this purpose, the MoPs trigger is not considered in the analysis presented in \autoref{chap:neural-network-triggers}. The implications of this choice are layed
out in \autoref{sec:classical-triggers-performance}.

\todo{correct this}
\todo{pseudocode?}

\subsection{Compatibility mode}
\label{ssec:compatibility-mode}

\begin{figure}
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./plots/time_trace_UUB.png}
		\caption{\textbf{UUB time trace}}
		\label{fig:uub-time-trace}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./plots/time_trace_UB.png}
		\caption{\textbf{UB time trace}}
		\label{fig:ub-time-trace}
	\end{subfigure}
	\caption{\textbf{(a)} A simulated signal as it would appear to UUB electronics. The ionizing particles originating in the extensive air shower hit the tank 
	around bin 660 ($\approx\SI{5.5}{\micro\second}$). \textbf{(b)} The same signal but filtered and downsampled to emulate UB electronics.}
	\label{fig:uub-ub-comparison}
\end{figure}

Altough the triggers discussed in the previous subsections are meant to function completely autonomously in the SD field, their implementation requires some prior 
knowledge of the signal one desires to detect. For their use in the Auger observatory, several hyperparameters such as the thresholds of the Th-Trigger, or the 
window size of the ToT-trigger have been determined in studies (\cite{bertou2006calibration}, \cite{triggerSettings}, \cite{ToTtriggerSetting}). 

These studies were conducted using the predecessor, the \textbf{U}nified \textbf{B}oard (UB), of the hardware that is being installed during the AugerPrime upgrade 
of the observatory. Most importantly, the \textbf{U}pgraded \textbf{U}nified \textbf{B}oard (UUB) has a sampling rate that is three times larger
(\SI{120}{\mega\hertz}) than that of UB electronics (\SI{40}{\mega\hertz}). Not only does this raise the number of bins in a standard time trace from 682 to 
$2^{11} = 2048$, but also drastically reduces the efficiency (in particular for ToT-like triggers) of the above discussed algorithms. Whereas a new FADC bin is 
measured every \SI{25}{\nano\second} in a UB station, the triggers would receive a new input every $\approx\SI{8.3}{\nano\second}$ in a UUB setting.

The modus operandi elected by the Pierre Auger collaboration to circumvent this problem is to emulate UB electronics using the UUB electronics. This means that 
measured FADC bins are to be filtered and downsampled before any trigger runs over them. Software implementations by which this is achieved are listed in 
\autoref{app:filter-and-downsample}. The effect the filtering and downsampling has on measured data is visualized in \autoref{fig:uub-ub-comparison}. 

\todo{comment on accuracy fo this method}

\section{Performance}
\label{sec:classical-triggers-performance}

The performance of a trigger can be evaluated in many different ways. In the most general consideration, a confusion matrix holds information about the ability of 
a classifier to discern between different types, or classes, $\mathcal{C}$. With the example at hand there exist two types of events one wishes to distinguish, a 
signal event $\mathcal{C}_1$ in the form of an extensive air shower, versus background $\mathcal{C}_0$. The confusion matrix thus becomes:

\begingroup
\renewcommand{\arraystretch}{1.5}
\begin{center}
	\begin{tabular}{@{}cc c|c@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{\scriptsize Predicted $\mathcal{C}$ \normalsize} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c}{$\mathcal{C}_1$} & 
		\multicolumn{1}{c}{$\mathcal{C}_0$} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{\scriptsize True $\mathcal{C}$ \normalsize}}
		& $\mathcal{C}_1$  & True positive (TP) & False negative (FN)   \\
		\cline{3-4}
		& $\mathcal{C}_0$  & False positive (TP) & True negative (TN) \\ 
		\cline{2-4}
	\end{tabular}
\end{center}
\endgroup

From this, other potentially interesting variables can be derived. Of particular interest for the Auger observatory are the sensitivity and \textbf{F}alse 
\textbf{D}iscovery \textbf{R}ate (FDR). The former is the probability that a signal event will be classified correctly, i.e. an extensive air shower hits a 
water tank and raises a T2 trigger. The sensitivity - in the following also called the trigger efficiency $\epsilon$ - is defined as

\begin{equation}
	\label{eq:statistics-efficiency}
	\epsilon = \frac{\text{TP}}{\text{TP} + \text{FN}}.
\end{equation}

The latter is a measure of how readily the triggers (wrongly) identify background events like stray cosmic muons as extensive air showers. It is imperative 
for any trigger algorithm operating in the SD to minimize this probability. Simply due to the number of operating stations in the field, a small increase in 
$\text{FDR}$ drastically raise the amount of potential events and hence load on the central analysis server of the observbatory.

\begin{equation}
	\label{eq:statistics-efficiency}
	\text{FDR} = \frac{\text{FP}}{\text{TP} + \text{FP}}.
\end{equation}

\todo{continue writing about performance}