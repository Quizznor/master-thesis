% !TEX root = ../thesis.tex

\chapter{Neural network triggers}
\label{chap:neural-network-triggers}

\todo{write introductory shit here?}

\section{Motivation}
\label{sec:motivation}

The station-level triggers in the previous chapter have been shown to perform well for the science case of the Pierre Auger Observatory. However, it has 
also been concluded that a lot of potential data, especially at low energies is ignored. This is by intention in order to keep DAQ readout at feasible levels.

Attempts at improving the overal efficiency of the SD triggers can be made. This is only possible to a certain level. At lowest energies the particle cascade is 
not big enough to warrant coincident triggers in at least 3 WCD stations. As per \autoref{sssec:bayesian-folding}, the lateral trigger probability a given 
classification algorithm can maximally achieve is given by the LPP (c.f. \autoref{fig:fitfunction-comparison}). The T3 detection probability of such an ideal 
trigger, and consequently the maximal efficiency for an array with $\SI{1.5}{\kilo\meter}$ spacing is compared to the efficiency of classical triggers in 
\autoref{fig:ideal-efficiency-comparison}.

Of course, efficiency can be improved simply by adjusting trigger thresholds of the algorithms in \autoref{sec:trigger-implementation}. However, the more lenient
these thresholds are, the more background events will be detected. This quickly results in trigger rates that are unmanagable for the infrastructure at the Pierre 
Auger observatory. The probability with which time traces correctly raise a T2 is shown alongside the resulting random-trace trigger rate for different thresholds
of classical algorithms in \autoref{fig:classical-trigger-roc}.

Ideally, neural network architectures developed in this chapter should undercut the random-trace trigger rate of classical triggers, while retaining an overall 
higher accuracy. That is, they lay below and right of the operating point in \autoref{fig:classical-trigger-roc}. For any algorithm that achieves this, the 
corresponding LTP will be greater than that of classical triggers, resulting in higher event detection efficiency, while not exceeding the bandwidth limitations 
of the underlaying hardware. 

\begin{figure}
	\begin{subfigure}[b]{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./plots/ideal_t3_efficiency.png}
		\caption{\textbf{T3 efficiency}}
		\label{fig:ideal-efficiency-comparison}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./plots/classical_trigger_ROC.png}
		\caption{\textbf{Classical trigger potential}}
		\label{fig:classical-trigger-roc}
	\end{subfigure}
	\caption{\textbf{(a)} Comparison of an ideal trigger sensitive to any shower signal from primary energies $E\geq\SI{10}{\peta\electronvolt}$ to classical 
    triggers. \textbf{(b)} The noise level over calculated efficiency for classical triggers. The tail ends of the potential curve are calculated by adjusting the
    trigger thresholds from $+250\%$ to $-95\%$ of the nominal values.}
\end{figure}

\section{Design considerations}
\label{sec:design-considerations}

The hardware specifications at the FPGA level, where trigger conditions are currently checked, are limited. For this reason, NN architectures should be kept as 
simple as possible. Most importantly, the number of weights, biases and other trainable parameters will need to be hardcoded into station software. Because of 
minimal available storage space, this number needs to be kept low.

This immediately disqualifies powerful candidates like autoencoders or transformers (compare \autoref{sec:NN-other}) from consideration, due to their size. Only 
simple dense-, convolutional-, and recurrent neural networks are viable contenders that could theoretically be implemented in the SD electronics.

\subsection{Implementation}
\label{ssec:implementation}

The python library TensorFlow \cite{tensorflow2015-whitepaper} is used as a backend to implement the individual classifiers. All discussed architectures are built 
and trained with the release version 2.8.4 \cite{tensorflowversion}. Adjustments to the trainable parameters are calculated according to a momentum-based 
stochastic gradient descent (Adam \cite{kingma2014adam}) on a batch level. In this context, a single batch is made up of all traces that are recorded from a single 
air shower event. Since batch size grows quickly with increasing energy, a generative approach, where traces are created (c.f. \autoref{sec:trace-building}) at 
runtime upon requirement, is used in building training data in order to make the process as RAM-efficient as possible. This has important implications. As trace 
building relies heavily on randomization, the actual training data will not be the same if the random number generators are not seeded beforehand. This has been
taken into account. All networks are - unless specifically stated otherwise - trained and validated using the same signal input data.

\subsection{Choice of input data}
\label{ssec:input-data}

As stated in the previous chapters, neural networks learn by example.

\subsubsection{Prior probability}
\label{sssec:prior-discussion}

The flux of cosmic rays with energies exceeding the proton knee is tiny ($\mathcal{O}(\SI[per-mode=power]{1}{\per\meter\per\year})$ \cite{dembinski2017data}). 
While the size of the SD guarantees decent exposure over the entire array, an individual station will mostly measure background. In fact, the prior probability $p$ 
of encountering such events in a given random time trace is roughly 1 in 1 000 000. Of course, an accurate prior during training would thus result in poor network 
performance. On the notion of a broken clock being correct twice a day, a naive classifier can have near perfect accuracy by labelling every input as background. 
Such behaviour is not desired. The prior probability must be artificially inflated. The influence of prior probability on subsequent trigger sensitivity is shown 
in \autoref{fig:prior-discussion}. No strong correlation between prior and network performance is found in the range $0.05 \leq p \leq 0.95$. As long as the 
fraction of signal over entire training set is statistically relevant, the network learns to discern between the signal and background. Nevertheless, a 
conservative prior of $p=0.5$ is picked for the following analysis.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{REPLACE ME}
	\caption{A very faint positive slope ($m = 0.02\pm0.01$) is observed when relating prior probability to trigger sensitivity (blue dots). This could however be 
	attributed to statistical fluctuations in the training fit. An ensemble of networks trained on the same data and with the same prior shows a comparable spread
	(orange dots).}
	\label{fig:prior-discussion}
\end{figure}

\subsubsection{Filtering \& Downsampling}
\label{sssec:filtering-and-downsampling}



\subsubsection{Loss function weighting}
\label{sssec:loss-function-weighting}

\subsection{Further hyperparameters}
\label{ssec:hyperparameters}





\section{Performance}

\begin{enumerate}
    \item Have problem
    \item Throw math at problem
    \item ???
    \item Profit
\end{enumerate}

\todo{write this}