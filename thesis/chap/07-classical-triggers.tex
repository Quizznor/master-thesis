% !TEX root = ../thesis.tex

\chapter{Classical station triggers}
\label{chap:classical-triggers}

As mentioned in \autoref{chap:auger-observatory}, continously analyzing data sent to CDAS from each of the 1600 SD water tanks would quickly exceed the 
computational capabilites of Augers' main servers. For this purpose, trace information is only collected from a station, once a nearby T3 event 
(c.f. \autoref{sssec:t3-trigger}) has been detected. The formation of a T3 trigger is dependant on several T2, or station-level, triggers, which will
be discussed in detail in this chapter. First, general comments about evaluation of trigger performances are given in 
\autoref{sec:classical-triggers-performance}. Then the precise implementation of SD station level triggers, as well as their individual performance is given in 
\autoref{sec:trigger-implementation}.

\section{Performance evaluation}
\label{sec:classical-triggers-performance}

The performance of a trigger can be evaluated in many different ways. In the most general consideration, a confusion matrix holds information about the ability of 
a classifier to discern between different types, or classes, $\mathcal{C}$. With the example at hand there exist two types of events one wishes to distinguish, a 
signal event $\mathcal{C}_1$ in the form of an extensive air shower, versus background $\mathcal{C}_0$. The confusion matrix thus becomes:

\begingroup
\renewcommand{\arraystretch}{1.5}
\begin{center}
	\begin{tabular}{@{}cc c|c@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{\scriptsize Predicted $\mathcal{C}$ \normalsize} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c}{$\mathcal{C}_1$} & 
		\multicolumn{1}{c}{$\mathcal{C}_0$} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{\scriptsize True $\mathcal{C}$ \normalsize}}
		& $\mathcal{C}_1$  & True positive (TP) & False negative (FN)   \\
		\cline{3-4}
		& $\mathcal{C}_0$  & False positive (TP) & True negative (TN) \\ 
		\cline{2-4}
	\end{tabular}
\end{center}
\endgroup

From this, other potentially interesting variables can be derived. Of particular interest for the Auger observatory are the sensitivity and \textbf{F}alse 
\textbf{D}iscovery \textbf{R}ate (FDR). The former is the probability that a signal event will be classified correctly, i.e. an extensive air shower hits a 
water tank and correctly raises a T2 trigger. The sensitivity - or \textbf{T}rue \textbf{P}ositive \textbf{R}ate (TPR) - is the ratio of correctly identified
signals over all signals.

\begin{align}
	\label{eq:statistics-efficiency}
	\text{TPR} &= \sum\limits_{\{\text{TP}\}} \frac{1}{w}, \qquad\text{where}\;w = \text{TP} + \text{FN}, \\
	\Leftrightarrow \qquad\qquad &= \frac{\text{TP}}{\text{TP} + \text{FN}}.
\end{align}

The $\text{TPR}$ for a given sample heavily depends on the underlaying distribution of data. While the distribution of zenith angles is correctly modeled, the 
simulated showers at hand do not accurately match the energy flux seen in real data (compare \autoref{fig:physics-data} and \autoref{fig:cr-energy-spectrum}). For
this purpose, the TPR for a given dataset is transformed to a conditional trigger efficiency $\epsilon$ by recalculating the weights $w_i$ based on the primary 
energy $E_i$ of a shower. First, the overrepresentation of higher energy traces is eliminated. Every prediction is weighted by a factor 
$b_{E_i}/b_{E_\text{ref}}$, where $b_{E_i}$ is the number of traces in a bin corresponding to energy $E_i$ (see \autoref{fig:physics-data}). Afterwards, a flux 
factor is multiplied to the weight. It is of the form $E_i^{-3}/{E_\text{ref}}$. Lastly, the thus calculated sum is normalized to the weight 
$W = \sum\limits_{\{\text{TP}, \text{FN}\}} \frac{1}{w_i}$ of the entire dataset.

The physical interpretation of $\epsilon$ for a classifier is as follows: (At station level) It represents the ratio of air showers that \textit{are} detected over
all air showers that \textit{can} in principle be detected. It is a conditional probability dependant on the WCD receiving a particle from an air shower. An 
efficiency of $epsilon = 1$ thus implies that if at least one particle in the shower cascade hits a tank, the tank raises a T2 trigger.

The false discovery rate is a measure of how readily the triggers (wrongly) identify background events like stray cosmic muons as extensive air showers. It is 
imperative for any trigger algorithm operating in the SD to minimize this probability. Simply due to the number of operating stations in the field, a small 
increase in $\text{FDR}$ drastically raises the amount of potential events and hence load on the central analysis server of the observatory.

\begin{equation}
	\label{eq:statistics-efficiency}
	\text{FDR} = \frac{\text{FP}}{\text{TP} + \text{FP}}.
\end{equation}

In this work, the trigger rate on random-traces $f_\text{Random}$ is used as an alias for the $\text{FDR}$. Of course, this is not completely accurate, as these 
to a small fraction contain signal from air showers. In any case, the distinction does not matter. Any trigger algorithm must have a sufficiently low trigger 
frequency on measured data - be it extensive air showers or background events - as to not overload CDAS readout capabilities.

Consequently a pseudo-score can be assigned to each classification algorithm in order to compare them. This score $a$ is given by \autoref{eq:comparison-score}.

\begin{equation}
	\label{eq:comparison-score}
	a = \frac{\epsilon}{f_\text{Random}\;[\SI{}{\hertz}]}
\end{equation}

The physical interpretation of this variable is not straight forward. If labels were known for random-trace datasets, $a$ would be equivalent to the 
\textbf{S}ignal-to-\textbf{N}oise \textbf{R}atio (SNR) of the classifier. However, since $f_\text{Random}$ and the T2 efficiency across all primary energies and 
zenith angles must be determined using two different sets of data, only a (positive) correlation between the two exists.

In conclusion, all algorithms should maximize $a$, i.e. boost the T2 trigger efficiency, while keeping the random-trace trigger rate as low as possible.

\subsection{Lateral Trigger Probability (LTP)}
\label{ssec:lateral-trigger-probability}

Ultimately, all test statistics constructed by classical station triggers (ignoring MoPS, c.f. \autoref{sec:trigger-implementation}) are correlated to the deposited 
charge $S$ in the WCD. Because $S$ is heavily influenced by the primary particle energy, zenith and distance to the shower core, as well as to a lesser extent by 
shower age and statistical fluctuations, it makes sense to parametrize the trigger efficiency $\epsilon(E, \theta, \text{SPD})$ in terms of these observables. 

From a heuristic consideration, it can immediately be concluded that large separations between station and shower axis affect efficiencies negatively, because the 
particle distribution function monotonically decreases with increasing $r$ (compare \autoref{fig:component-LDF}). Similarly, inclined showers with a large $\theta$
are more attenuated compared to vertical showers, as they have to traverse a larger atmospheric depth ($\propto\sec\left(\theta\right)$) before reaching the 
detector. Lastly, primaries with large $E$ on average deposit higher $S$ in the WCD due to unleashing bigger particle cascades. Consequently $\epsilon$ is 
positively correlated with $E$.

The functional form that can be obtained by evaluating trigger efficiencies for a given (slice of) $E$ and $\theta$ is labelled the \textbf{L}ateral 
\textbf{T}rigger \textbf{P}robability (LTP). It will be one of the main comparison metrics, by which different trigger algorithms are compared in this work. For 
classical triggers, two methods to extract the LTP are presented here. This is to show that both yield comparable results, and the latter method is a fair 
estimator for the neural network LTPs discussed in \autoref{chap:neural-network-triggers}.

\subsubsection{\Offline lateral trigger probability}
\label{sssec:offline-ltp}

\Offline can simulate the SD detector response given a preprocessed shower footprint as given by e.g. CORSIKA. As such, calculating the LTP for a given event
condenses to counting the number of triggered and non-triggered stations at specific distances from the shower axis. If this is done for a large enough sample size
of showers, one eliminates noise induced by shower-to-shower fluctuations and arrives at an independent estimator for the probability of a T2 trigger given a 
shower at a shower plane distance $r$, with energy $E$ and zenith $\theta$. As per \cite{abreu2011lateral}, the closed form approximation of the LTP is given as

\begin{equation}
	\label{eq:offline-ltp}
	\text{LTP}\left(r\right) = 
	\begin{dcases}
		\frac{1}{1 + \exp\left(\frac{r - R_0}{\sigma_R}\right)}, \qquad r \leq R_0 \\
		\frac{1}{2} \exp{\left(C(r-R_0)\right)},\;\;\;\,r > R_0
	\end{dcases}
\end{equation}

In \autoref{eq:offline-ltp}, $R_0$, $\sigma_R$ and $C$ are all fit constants that will in general depend on $E$ and $\theta$. Most importantly, $R_0$ marks the 
shower plane distance where $\text(R_0) = 0.5$. This is connected to a steepening of the rising flank in the efficiency curve. Whereas an exponential function with
decay constant $C<0$ describes data well for large $r$, a logistic function with scaling factor $1/\sigma_R$ must account for the asymptotic transition to full 
efficiency closer to the core.

It must be mentioned that the motivation behind this parametrization is data- and not physics driven. In particular, $\text{LTP}(r)$ is not smooth in $R_0$ if the 
parameters $C$ and $\sigma_R$ are not finetuned as indicated in \autoref{eq:smoothness-requirement}.

\begin{equation}
	\label{eq:smoothness-requirement}
	\lim\limits_{r \to R_0^+} \frac{\partial\,\text{LTP}(r)}{\partial r} = \frac{C}{2} \;\; \stackrel{!}{=} \;\; \frac{1}{4\sigma_R} = \lim\limits_{r \to R_0^-} \frac{\partial\,\text{LTP}(r)}{\partial r}
\end{equation}

In this work however, a different parametrization is used to estimate the T2 response of a station. The functional form of this adjusted trigger probability is
a clipped logistic function, and given in \autoref{eq:my-ltp}.

\begin{equation}
	\label{eq:my-ltp}
	\text{LTP}^*(r) = \min\left(1,\,\epsilon^*\,\left(1 - \frac{1}{1+e^{-\frac{r-R_0}{\sigma_R}}}\right)\right)
\end{equation}

The reasoning for this choice is as follows:

\begin{itemize}
	\item The original parametrization, $\text{LTP}(r)$, eventually approaches $1$. This hints to a problem. It is not a guarantee that some trigger algorithm will
	detect all extensive air showers. Espically neural network triggers  might be sensitive to only a subset of showers. This is reflected in the latter form, 
	$\text{LTP}^*(r)$, by introducing an additional fit parameter, the pseudo-efficiency $0\leq\epsilon^*<2$. In the case of $\epsilon^*\geq1$, the domain of the 
	function is correctly mapped to $[0, 1]$.

	\item There exists an imbalance in training data. Due to the geometry of the SD array, more traces at smaller $r$ are available. In an attempt to reduce 
	possible biases resulting from low statistics at small SPD, the form is kept as simple as possible.

	\item The function is guaranteed to be continously differentiable in $R_0$. For values $\epsilon^* > 1$ this is replaced with a kink at 
	$R^* = R_0 - \frac{\log\left(\left(1 - 1/\epsilon^*\right)^{-1}-1\right)}{\sigma_R}$, where $\text{LTP}^*(r)$ would exceed $1$ if not for clipping. There 
	exists some physical motivations for this however. Due to the phase transition, namely to full efficiency, at this point, discontinuities in the lateral 
	trigger probability are allowed.
\end{itemize}

This approach only marginally takes into account shower-to-shower-fluctuations. Such statistic perturbations are responsible for a smearing of the (initially)
hard transition from sub- to full efficiency. The parametrization used by the Pierre Auger collaboration takes this into consideration by design.The presented 
$\text{LTP}^*(r)$ does - at least explicitly - not. As a result, one could expect a bias, where $\text{LTP}^*(R^*)$ over- or underestimates the actual trigger 
probability. This is however not the case when examining the residuals of the performance fit that is done in \autoref{ssec:combined-performance}. A plot 
showcasing this is offered in \autoref{fig:fitfunction-comparison}. Still, results at low energies ($\log(E\,/\,\mathrm{eV}) < 17.5$) must be taken with a hint of 
skepticism, as only very little data is available for such showers.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{./plots/LTP_bias_check.png}
	\caption{The residuals from comparing $\epsilon^\text{True}$ to $\text{LTP}^*(r)$ vanish at large (small) $r$. No systematic bias is observed in the 
	transitional region around $R^*$. Large outliers are caused by the dataset being limited in size at low energies (marked with an x).}
	\label{fig:fitfunction-comparison}
\end{figure}

\subsubsection{Bayesian folding}
\label{sssec:bayesian-folding}

Given a time trace of the form in \autoref{chap:neural-network-data}, it is easy to determine whether or not a given trigger algorithm analyzing this trace would
raise a T2. The trigger probability obtained this way must however not be confused with the lateral trigger probability discussed above. It is the conditional 
probability of a T2 given that a tank receives an air shower signal, $P(\text{T2}\,|\,\mathcal{C}_1)$. The complete LTP can be calculated in the following form:

\begin{equation}
	\label{eq:bayesian-folding}
	\text{LTP} := P(\text{T2}) = P(\text{T2}\,|\,\mathcal{C}_1) * P(\mathcal{C}_1).
\end{equation}

$P(\mathcal{C}_1)$ in \autoref{eq:bayesian-folding} is the \textbf{L}ateral \textbf{P}article \textbf{P}robability (LPP) and quantifies the chance of a station 
receiving a signal from an extensive air shower. It is the probabilistic interpretation of the lateral distribution function (c.f. \autoref{fig:component-LDF}). 
The LTP of an ideal classifier that is able to identify individual particles would be equal to the LPP.

For this work, the LPP is calculated by comparing the simulated stations in \autoref{sec:signal-dataset} to a catalog of known stations in the vicinity of the 
shower core. The ratio of simulated stations divided by all stations at a specific SPD is the LPP at a given (slice of) energy $E$ and zenith $\theta$. A 
function like in \autoref{eq:my-ltp} is fitted to the data to extrapolate values at arbitrary SPD. The result of this analysis for all energies and zenith angles
is shown in \autoref{fig:lateral-particle-probability}. The best fit parameters are listed in \autoref{app:lpp-fit-parameters}.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{./plots/LPP.png}
	\caption{The probability of a station receiving a particle in relation to its' separation from the shower core axis. The probability at a constant SPD 
	increases with increasing primary energy, but decreases with increasing zenith angle.}
	\label{fig:lateral-particle-probability}
\end{figure}

The comparison between the LTP gathered via Bayesian folding is compared to the \Offline station counting approach in \autoref{sec:trigger-implementation}. This is
done for every classical trigger individually. It is found that no remarkable difference between both results exists. As a consequence, this method of evaluating 
the LTP allows for an easy comparison of neural network triggers to the algorithms discussed in the following. 

\subsection{Calculation of T3 efficiency}
\label{ssec:t3-calculation}

When transitioning from station- to event-level, the important variable becomes the T3 efficiency. It states the probability of a shower not only being detected
in individual stations, but also identified as such by the CDAS T3 triggers. In the end, the only measured data that is available comes from extensive air showers
which passed this final hurdle.

With the lateral trigger probability at hand, a simple Monte-Carlo simulation can recover the T3 efficiency. Recall that the probability of a single station $i$
detecting a shower at distance $r_i$, with energy $E$ and arrival direction $(\theta, \phi$) is given by \autoref{eq:station-trigger-probability}.

\begin{equation}
	\label{eq:station-trigger-probability}
	\text{LTP}^*(r_i) = \min\left(1,\,\epsilon^*(E, \theta)\,\left(1 - \frac{1}{1+e^{-\frac{r_i-R_0(E, \theta)}{\sigma_R(E, \theta)}}}\right)\right).
\end{equation}

In the simplest case, this results in a T3 trigger if the three closest stations raise a T2 within \SI{11}{\micro\second} of one another. By simulating a random
core position and determining the detector response, one can calculate the event detection numerically. The approach presented here does not take into account 
timing differences resulting from the finite propagation speed of the shower front. Instead, it is assumed that all stations simultaneously receive a signal. This
is only accurate if the primary particle initiated a perfectly vertical cascade infinitely far away from the SD. However, due to the permissivity of the T3 
triggers such considerations need not be accounted for. Even in the most suboptimal case of a horizontal shower ($\theta = 90^\circ$), the furthest station in the 
triangle receives a signal latest around $\frac{\SI{1.5}{\kilo\meter}}{c} = \SI{5}{\micro\second}$ after the closest one. Exemplary simulations and resulting T3 
efficiencies for classical triggers are shown in \autoref{fig:t3-mc-simulation} and further discussed in \autoref{ssec:combined-performance}.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{./plots/t3_mc_simulation.png}
	\caption{(\textit{Left}) An example of randomized core positions color- and size-coded according to zenith and primary energy. Showers that raised a T3 are 
	shown in the green unit triangle. The ones that do not are displayed in the red part. The stations at the vertices of the SD unit triangle are shown as black
	circles. (\textit{Right}) The ratio of triggered vs. all showers, with respect to primary energy and shower inclination.}
	\label{fig:t3-mc-simulation}
\end{figure}

\section{Implementation}
\label{sec:trigger-implementation}

\subsection{Threshold trigger (Th)}
\label{ssec:threshold-trigger}

The \textbf{Th}reshold trigger (Th) is the simplest, as well as longest operating trigger algorithm \cite{triggerGuide} in the field. It scans incoming 
ADC bins as measured by the three different WCD PMTs for values that exceed some threshold. If a coincident exceedance of this threshold is observed in 
all three WCD PMTs simultaneously, a Th-T1/2 trigger is issued. A pseudocode implementation of this algorithm is hence given by the below code block.

\begin{lstlisting}
 th1 = 1.75  // Th1 level threshold above baseline, in VEM   
 th2 = 3.20  // Th2 level threshold above baseline, in VEM  

 while True:

     pmt1, pmt2, pmt3 = get_next_output_from_WCD()

     if pmt1 <= th2 and pmt2 <= th2 and pmt3 <= th2:
         raise ThT1_trigger
     if pmt1 <= th1 and pmt2 <= th1 and pmt3 <= th1:
         raise ThT2_trigger
     else: 
         continue
\end{lstlisting}

Logically, with increasing signal strength $S$ in the PMTs, the likelihood of having observed an extensive air shower raises. This is reflected in the trigger 
level logic, where a coincident signal of $S\leq\SI{3.20}{\Peak}$ is immediately forwarded to CDAS, whereas a signal $\SI{1.75}{\Peak}\leq S<\SI{3.20}{\Peak}$ 
only raises a Th-T1 trigger. The algorithm is insensitive to signals that do not exceed at least $\SI{1.75}\Peak$ in all three PMTs.

In the case of faulty electronics, where only a subset of the WCD PMTs are available, the trigger thresholds (in units of \SI{}{\Peak}) are updated according to 
\autoref{tab:trigger-thresholds}.

\begin{table}[h]
	\begin{center}
	\caption{Numerical values from \cite{triggerSettings}}
	\begin{tabular*}{0.4\textwidth}{@{\extracolsep{\fill}} ccc}
		\toprule
		$n_\text{PMT}$ & Th-T2 & Th-T1 \\
		\midrule
		1 & 5.00 & 2.85 \\
		2 & 3.60 & 2.00 \\
		3 & 3.20 & 1.75 \\
		\bottomrule
	\label{tab:trigger-thresholds}
	\end{tabular*}
	\end{center}
\end{table}

\subsubsection{Performance}
\label{ssec:th-performance}

The average trigger rate for the Th-T2 trigger per station is \textit{defined} to be $\approx\SI{20}{\hertz}$ (c.f. \autoref{ssec:online-calibration}). Comparing 
this to the nominal T3 trigger rate at CDAS level ($\approx\SI{0.03}{\hertz}$ \cite{abraham2010trigger}) over the entire array, it becomes obvious that a lot of 
background events pass this threshold. Consequently, the trigger has a very high false discovery rate on a station to station level
$\text{FDR}\approx\frac{\SI{20}{\hertz} - \SI{0.03}{\hertz}/1600}{\SI{20}{\hertz} + \SI{0.03}{\hertz}/1600}=0.999998$.

The efficiency of the threshold trigger is comparably poor. Only every fifth trace ($\epsilon = 0.2$) is detected as such. This number must however be taken with 
context. In \autoref{chap:neural-network-data}, a signal is considered to be any kind of detector response from an extensive air shower. This includes single muons
injected into WCDs faraway from the shower core. As such, the dataset that triggers are being tested on contain a lot of information algorithms were designed to 
ignore. This drops the efficiency considerably. Nevertheless, it serves as a gauge to compare this trigger to the ones discussed on the following pages.

While this may seem like an indigent method of shower detection, the threshold trigger is invaluable in the search for neutrino cosmic rays. The EM component of 
such showers is heavily attenuated due to their inclination ($\theta \geq 65^\circ$). Only the muonic component reaches the SD detector. The threshold trigger 
ensures the array is sensitive to such events, at the cost of a high background noise. 

The lateral trigger probability for the Th-T2 type trigger is shown in \autoref{fig:th2-ltp-comparison}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{./plots/th2_LTP_comparison.png}
	\caption{The lateral trigger probability for the threshold T2 trigger. Shown is the comparison between the different procedures discussed in 
	\autoref{sec:classical-triggers-performance}. Both results agree across all considered primary energies and zenith angles.} 
	\label{fig:th2-ltp-comparison}
\end{figure}

\subsection{Time over Threshold trigger (ToT)}
\label{ssec:time-over-threshold-trigger}

The \textbf{T}ime \textbf{o}ver \textbf{T}hreshold trigger (ToT) is sensitive to much smaller signals than the Threshold trigger discussed in 
\autoref{ssec:threshold-trigger}. For each PMT in the water tank, the past 120 bins are examined for values that exceed $\SI{0.2}{\Peak}$. If 13 or more bins
above the threshold are found in the window - ordering or succession do not matter - the PMT is considered to have an elevated pedestal. The ToT trigger requires
at least two PMTs with an elevated pedestal in order to activate. As such, the algorithm is theoretically sensitive to events that deposit just $~\SI{0.5}{\Charge}$ 
A pseudocode example is given below.

\begin{lstlisting}
 threshold   = 0.2  // pedestal threshold, in VEM
 n_bins      = 12   // number of bins above pedestal
 window_size = 120  // considered window length

 buffers = [[False for i in 1..window_size] for j in 1..3] 
 step_count = 0

 while True:

     pmts = get_next_output_from_WCD()
     buffer_index = step_count % window_size
     count_active_PMTs = 0

     for pmt, buffer in pmts, buffers:
         if pmt <= threshold: buffer[buffer_index] = True

         if count_values(buffer, value = True) > n_bins:
             count_active_PMTs += 1

     if count_active_PMTs >= 2:
         raise ToTT2_trigger
     else:
         step_count = buffer_index + 1
         continue
\end{lstlisting}

\subsubsection{Performance}
\label{ssec:tot-performance}

The nominal operation of the ToT algorithm sees a trigger rate of \SI{2}{\hertz}. While this still corresponds to a relatively large $\text{FDR}$, the signal to 
noise ratio is at least an order of magnitude better than Th-T2, simply by arguments of trigger frequency. Moreover, coincidences between neighbouring stations are
likely to be extensive air showers. Events selected from ToT issued T3s have a purity of 90\%, and are the main detection channel for showers with inclination 
$\theta < 60^\circ$ \cite{abraham2010trigger}. The ToT trigger itself has an efficiency of $\epsilon = 0.3969$ when evaluated over the neural network training 
dataset. The trigger probability w.r.t shower plane distance is shown for different primary energies and different arrival directions in 
\autoref{fig:tot-ltp-comparison}.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{./plots/tot_LTP_comparison.png}
	\caption{The lateral trigger probability for the time-over-threshold trigger for Bayesian folding and \Offline station counting.} 
	\label{fig:tot-ltp-comparison}
\end{figure}

\subsection{Time over Threshold deconvoluted trigger (ToTd)}
\label{ssec:time-over-threshold-deconvoluted}

An extension to even lower signal strengths is given by the \textbf{ToT}-\textbf{d}econvoluted trigger (ToTd). As the name implies, the implementation of the 
algorithm is completely analog to the ToT trigger in \autoref{ssec:time-over-threshold-trigger}. Only the FADC input stream from the three PMTs is altered 
according to \autoref{eq:trace-deconvolution}.

\begin{equation}
    \label{eq:trace-deconvolution}
    d_i = (a_i - a_{i-1}\cdot e^{-\Delta t/\tau})\,/\,(1 - e^{\Delta t/\tau}) 
\end{equation}

In \autoref{eq:trace-deconvolution}, the deconvoluted bin $d_i$ is calculated from the measured FADC values $a_i$ and $a_{i-1}$, where $a_{i-1}$ is scaled 
according to an exponential decay with mean lifetime $\tau = \SI{67}{\nano\second}$. This reduces the exponential tail of an electromagnetic signal to a 
series of pulses which in the case of $a_{i-1} < a_i$ exceed the original signal strength. As such, the deconvoluted trace can satisfy the ToT trigger 
requirements, whereas the original raw FADC values might not have, extending the sensitivity of the ToT trigger to lower signal strengths. The scaling constant 
$\Delta t = \SI{25}{\nano\second}$ is tied to the sampling rate of UB electronics (c.f. \autoref{ssec:sd-daq}). The choice of the numerical constants $\tau$ and 
$\Delta t$ is explained in more detail in \cite{ToTtriggerIdea}.

\subsubsection{Performance}
\label{ssec:totd-performance}

The performance of the ToTd trigger is very similar to that of the ToT discussed in \autoref{ssec:tot-performance}. It posesses a comparable efficiency
$\epsilon = 0.4027$ to its' convoluted counterpart. The lateral trigger probability for this algorithm is shown in \autoref{fig:totd-ltp-comparison}.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{./plots/totd_LTP_comparison.png}
	\caption{The lateral trigger probability for the time-over-threshold-deconvoluted trigger. Errorbars are plotted transparently in order to not overcrowd the 
	figure.} 
	\label{fig:totd-ltp-comparison}
\end{figure}

\subsection{Multiplicity of Positive Steps (MoPS)}
\label{ssec:multiplicity-of-positive-steps}

The \textbf{M}ultiplicity \textbf{o}f \textbf{P}ositive \textbf{S}teps (MoPS) algorithm triggers on positive flanks of an FADC trace, which can be related to the 
arrival of new particles in the water tank. 

A positive flank in the FADC trace of a single PMT is any combination of at least two bins that are monotonically increasing in value, in a window of 120 bins. 
Once such a positive step has been identified, a (MoPS) trigger veto is applied to the next 

\begin{equation}
    \label{eq:MoPS-veto}
    n_\text{skip} = \lfloor \left( \log_2(\Delta y) + 1 \right) - 3\rceil
\end{equation}

bins, where $\Delta y$ refers to the total vertical increase in the step from first to last bin. Note that in \autoref{eq:MoPS-veto} the notation 
$\lfloor x \rceil$ is used as shorthand notation to round $x$ to the nearest integer. If $\Delta y$ is bigger than $y_\text{min} = \SI{3}{\ADC}$ (to filter random 
fluctuations), but does not exceed $y_\text{max} = \SI{31}{\ADC}$ (to prevent triggering on muonic coincidences), it is added to a ledger. If the number of rising 
flanks in the ledger is bigger than $m>4$ for at least two PMTs, a final check regarding the integral of the FADC trace is performed. If this check passes, a 
MoPS-T2 trigger is issued to CDAS. An in-depth discussion of the different hyperparameters for this trigger is offered e.g. in \cite{gapMoPS}.

It is impossible to accurately recreate the MoPS trigger in simulations. The integral test above compares the sum of the last 250 bins against a threshold 
($\sum a_i$ > 75). Since not all 250 bin values are available to CDAS, differing results are to be expected when comparing the implementation of the algorithm in 
the SD field versus its' counterpart in analysis software. 

For this purpose, the MoPs trigger is not considered when comparing performances of classical triggers to those in \autoref{chap:neural-network-triggers}. The 
implications of this choice are layed out in the following paragraph.

\subsubsection{Performance}
\label{ssec:mops-performance}

By examining monitoring data, it follows that $1-2$ MoPS triggers are issued per station each minute. This corresponds to a trigger rate of 
$\SIrange[range-phrase = \,\text{to}\,]{0.02}{0.03}{\hertz}$. This is orders of magnitude lower than other discussed trigger mechanisms. While the MoPS trigger 
consequently can be seen as a relatively noise free trigger, events in which a MoPS is critically required to form a T3 are extremely sparse. From a total of 
$20000$ (simulated) showers at lower energies, none had a three-fold coincidence where at least one station only detected a MoPS T2 trigger. Considering this 
result, it is expected that T3 efficiencies are largely independant of the fact whether MoPS is considered or not.

\subsection{Combined performance}
\label{ssec:combined-performance}

In the field, all above discussed algorithms are run simultaneously. That is, a T2 trigger is issued whenever any of the Th-T2, ToT, ToTd, or MoPS trigger become 
active. This results in an overall trigger rate of roughly \SIrange[range-phrase = \,\text{to}\,]{22}{23}{\hertz}, with a combined efficiency of 
$\epsilon = 0.4070$. The combined lateral trigger probability with respect to shower plane distance is shown in \autoref{fig:all-triggers-ltp}. The overall T3 
efficiency as calculated in \autoref{ssec:t3-calculation} is shown in \autoref{fig:ideal-efficiency-comparison}. As can be seen in the plot, detection of air 
showers is guaranteed at primary energies of around $10^{18}\,\SI{}{\electronvolt}$ and upwards.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{./plots/all_LTP_comparison.png}
	\caption{The lateral trigger probability for the combination of all previously discussed trigger algorithms.} 
	\label{fig:all-triggers-ltp}
\end{figure}
